<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Background &#8212; Pseudorandomness Spring 2017 documentation</title>
    
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     'Spring 2017',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../seminar/index.html">Seminars</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html">Groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="../open_problems/index.html">Open Problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reading/index.html">Reading Lists</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <p>Notes from presentation by Russell Impagliazzo at the Simons Working Group on
Learning Models of Mathematical Objects.</p>
<p>Prepared by Holden Lee.</p>
<div class="section" id="background">
<h1>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h1>
<p>A theme that cuts across many domains of computer science and
mathematics is to find simple representations of complex mathematical
objects such as graphs, functions, or distributions on data. These
representations need to capture how the object interacts with a class of
tests, and to approximately determine the outcome of these tests.</p>
<p>For example, in machine learning, the object might be a distribution on
data points, high dimensional real vectors, and the tests might be
half-spaces. The goal would be to learn a simple representation of the
data that determines the probability of any half-space or possibly
intersections of half spaces. In computational complexity, the object
might be a Boolean function or distribution on strings, and the tests
are functions of low circuit complexity. In graph theory, the object is
a large graph, and the tests are the cuts In the graph; the
representation should determine approximately the size of any cut. In
additive combinatorics, the object might be a function or distribution
over an Abelian group, and the tests might be correlations with linear
functions or polynomials.</p>
<p>The focus of the working group is to understand the common elements that
underlie results in all of these areas, to use the connections between
them to make existential results algorithmic, and to then use
algorithmic versions of these results for new purposes. For example, can
we use boosting, a technique from supervised learning, in an
unsupervised context? Can we characterize the pseudo-entropy of
distributions, a concept arising in cryptography? Do the properties of
dense graphs “relativize” to sub-graphs of expanders?</p>
<p>In particular, we’ll start from boosting, a technique in machine
learning to go from weak learning to strong learning, i.e., taking an
algorithm that learns a function only with a small correlation and
making one that learns the function on almost all inputs. We’ll show how
boosting implies a general Hardcore Distribution Lemma, showing that any
function that cannot be <span class="math">\(1-\delta\)</span> approximated by simple
functions has a sub-distribution of size <span class="math">\(\delta\)</span> where it has
almost no correlation with simple functions. By starting from boosting,
we will be able to show a constructive version of this lemma. From the
Hardcore Distribution lemma, we’ll derive the Dense Model Theorem used
by Green and Tao to show arbitrarily long arithmetic progressions in the
primes. Again, by starting with boosting, we get a general algorithmic
version of DMT. This algorithmic version can then be used to derive a
general Weak Regularity Theorem, with that of Frieze and Kannan and
analogs for sparse graphs as a special case.</p>
<p>Hopefully, at this point, the working group will segue from known
connections to new connections, e.g., is there a strong boosting that
implies strong regularity? Can algorithmic regularity lemmas be used in
ML?</p>
<p>We won’t assume any background and will develop everything from first
principles using only simple calculations. Here’s an optional reading
list, and some papers we might refer to.</p>
<p>Papers with results we’ll cover:</p>
<ul class="simple">
<li>Klivans and Servedio, Boosting and Hard-core Sets, FOCS 99.</li>
<li>Omer Reingold, Luca Trevisan, Madhur Tulsiani, Salil P. Vadhan: Dense
Subsets of Pseudorandom Sets. FOCS 2008: 76-85</li>
<li>Luca Trevisan, Madhur Tulsiani, Salil P. Vadhan: Regularity,
Boosting, and Efficiently Simulating Every High-Entropy Distribution.
IEEE Conference on Computational Complexity 2009: 126-136</li>
<li>Russell Impagliazzo, Algorithmic Dense Model Theorems and Weak
Regularity</li>
<li>Sita Gakkhar Russell Impagliazzo Valentine Kabanets. Hardcore
Measures, Dense Models and Low Complexity Approximations</li>
</ul>
<ul class="simple">
<li></li>
</ul>
<p>Bibliography:</p>
<p>We won’t go through these papers explicitly, but they provide the
context.</p>
<ul class="simple">
<li>Robert E. Schapire: The Strength of Weak Learnability (Extended
Abstract). FOCS 1989: 28-33 : 01 June 2005 A desicion-theoretic
generalization of on-line learning and an application to boosting
Yoav Freund, Robert E. Schapire</li>
<li>Yoav Freund, Robert E. Schapire: Game Theory, On-Line Prediction and
Boosting. COLT 1996: 325-332</li>
<li>Russell Impagliazzo: Hard-Core Distributions for Somewhat Hard
Problems. FOCS 1995: 538-545</li>
<li>Thomas Holenstein: Key agreement from weak bit agreement. STOC 2005:
664-673</li>
<li>Boaz Barak, Ronen Shaltiel, Avi Wigderson: Computational Analogues of
Entropy. RANDOM-APPROX 2003: 200-215</li>
<li>Alan M. Frieze, Ravi Kannan: The Regularity Lemma and Approximation
Schemes for Dense Problems. FOCS 1996: 12-20</li>
<li>Noga Alon, Amin Coja-Oghlan, Hiêp Hàn, Mihyun Kang, Vojtech R&#8217;’odl,
Mathias Schacht: Quasi-Randomness and Algorithmic Regularity for
Graphs with General Degree Distributions. SIAM J. Comput. 39(6):
2336-2362(2010)</li>
<li>Noga Alon, Assaf Naor: Approximating the Cut-Norm via Grothendieck’s
Inequality. SIAM J. Comput. 35(4): 787-803 (2006)</li>
<li>Green, Ben; Tao, Terence (2008). “The primes contain arbitrarily long
arithmetic progressions”. Annals of Mathematics. 167 (2): 481–547.</li>
<li>Tao, Terence; Ziegler, Tamar (2008). “The primes contain arbitrarily
long polynomial progressions”. Acta Mathematica. 201 (2): 213–305</li>
</ul>
</div>
<div class="section" id="big-picture">
<h1>Big picture<a class="headerlink" href="#big-picture" title="Permalink to this headline">¶</a></h1>
<div class="line-block">
<div class="line">We’ll talk about several results which have different names in
different fields. You probably know them, but don’t know the same or
related idea comes up in the other fields.</div>
</div>
<table border="1" class="docutils">
<colgroup>
<col width="9%" />
<col width="32%" />
<col width="12%" />
<col width="29%" />
<col width="16%" />
<col width="2%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">&#160;</th>
<th class="head">Boosting</th>
<th class="head">Hard-core lemma</th>
<th class="head">Dense model theorem</th>
<th class="head">Weak regularity</th>
<th class="head">?</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Area</td>
<td>ML</td>
<td>CC, Derandom-ization</td>
<td>Additive combinatorics, CC</td>
<td>Graph theory</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>Credit</td>
<td>Shapiro, Freund-Schapire</td>
<td>Impagliazzo, Holenstein</td>
<td>Green-Tao, Barak-Shaltiel-Wigderson</td>
<td>Szemeredi, Frieze-Kannan</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>Get</td>
<td>Circuit computing <span class="math">\(f\)</span> <span class="math">\(1-\delta\)</span> of the time</td>
<td>”</td>
<td>Proof that set isn’t <span class="math">\(\delta\)</span>-dense</td>
<td>”</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>Unless</td>
<td>Weak learner fails on distribution of density <span class="math">\(\Omega(\delta)\)</span></td>
<td>Hard-core distribution</td>
<td><span class="math">\(\Omega(\delta)\)</span>-dense “model” indistinguishable from set</td>
<td>A model succinctly describing set</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>Algorithm needed</td>
<td>Weak learner</td>
<td>”</td>
<td>Distinguisher</td>
<td>”</td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<p>We will take these theorems that we know to be true and show
implications between them. Implications are due to...</p>
<ol class="arabic simple">
<li>Boosting<span class="math">\(\implies\)</span>Hard-core: Klivans and Servedio.</li>
<li>Hard-core<span class="math">\(\implies\)</span>Dense model: Impagliazzo</li>
<li>Dense model<span class="math">\(\implies\)</span>Weak regularity:
Trevisan-Tulsiani-Vadhan, Reingold-Trevisan-Tulsiani-Vadhan</li>
<li>Weak regularity<span class="math">\(\implies\)</span>boosting: Trevisan-Tulsiani-Vadhan</li>
</ol>
<p>What can we gain from looking at these connections?</p>
<ol class="arabic">
<li><p class="first">Versatility: We can “retrofit” algorithms for one setting to get
algorithms for the other settings.</p>
<p>For example, there are many boosting algorithms. When you follow this
progression, you get different quantitative and qualitative versions
of dense model theorem and regularity.</p>
</li>
<li><p class="first">Algorithmic and constructive results:</p>
<p>There are nonconstructive versions using the min-max theorem for
boosting, hard-core lemma, dense model theorem. We care about
algorithmic versions.</p>
<p>Note that the algorithmic result that we care about is different in
the different settings. In ML we care about getting a function that
computes a function much of the time. On the other side, we’re really
after the distribution where the weak learner fails, so that we get a
model that succinctly describes the set.</p>
<p>We pay attention to do the reductions in an algorithmic, not just an
existential way.</p>
</li>
<li><p class="first">Using the dense model theorem for learning. Can we take a boosting
technique and use it in an unsupervised way?</p>
</li>
<li><p class="first">Generality: some things seem to be specific to a setting (density of
graphs).</p>
<p>But actually, weak regularity doesn’t have anything to do with graphs
being dense. We can relativize it to subgraphs of any graph. You can
look at subgraphs of expanders, bipartite graphs, etc., and plug it
in the same machinery. Likewise if you want to look at spectral norms
rather than cuts.</p>
</li>
</ol>
<p>Here is a cartoon:</p>
<ol class="arabic">
<li><p class="first">Let <span class="math">\(X\)</span> be a set, e.g. a distribution of points in the square.
Let <span class="math">\(S\)</span> be some distribution on points in <span class="math">\(X\)</span>.</p>
<img alt="../_images/pic1.png" src="../_images/pic1.png" />
<p>Let <span class="math">\(\mathcal T\)</span> be a set of classifiers, ex. a set of
half-planes.</p>
<p>Let <span class="math">\(\mathcal F_K\mathcal T\)</span> be boolean functions on <span class="math">\(K\)</span>
functions in <span class="math">\(\mathcal T\)</span>; here, partitions into polygonal
regions by <span class="math">\(k\)</span> half-planes.</p>
<p>We want to pre-process the distribution to be able to answer queries
in <span class="math">\(\mathcal F_K\mathcal T\)</span>.</p>
</li>
<li><p class="first">A violation of pseudo-density in this setting means there is a
polygonal region with many more points from <span class="math">\(S\)</span> than its
volume, a “hot spot”.</p>
<img alt="../_images/pic2.png" src="../_images/pic2.png" />
<div class="math">
\[\text{Area}(\text{region})&lt; \delta \Pr_S (\text{region})-\varepsilon.\]</div>
</li>
<li><p class="first">A model is a partition into polygonal regions, with a probability
distribution on regions. A simple model is defined by at most
<span class="math">\(k\)</span> lines.</p>
<p>The property of a model is that we can estimate half-space
probabilities (“given any half-space, what proportion of points of
<span class="math">\(S\)</span> are on one side of it?”) by treating the points as if
uniform within regions.</p>
<img alt="../_images/pic3.png" src="../_images/pic3.png" />
</li>
<li><p class="first">The algorithmic requirement in order to process the points to answer
queries in <span class="math">\(\mathcal F_K\mathcal T\)</span> is: given a set of points
sampled from <span class="math">\(S\)</span>, and a set of points sampled from <span class="math">\(U\)</span>,
find a half-space that approximately maximizes the difference in
probabilities for these two sets. The equivalent in boosting is a
distinguishing algorithm.</p>
</li>
</ol>
<table border="1" class="docutils">
<colgroup>
<col width="4%" />
<col width="36%" />
<col width="25%" />
<col width="29%" />
<col width="5%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Setting</th>
<th class="head">Boosting</th>
<th class="head">Hard-core measure</th>
<th class="head">DMT/transference principle</th>
<th class="head">Weak regularity</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>&#160;</td>
<td>WL: <span class="math">\(|\mu_{i}|\ge2\delta\)</span>, <span class="math">\(\mu_{i}=g(h_{1,}\ldots,h_{i},f)\)</span>, <span class="math">\(h_{i+1}\in\mathcal{T}\)</span>, <span class="math">\(k\)</span> iterations</td>
<td>Hardcore measure: <span class="math">\(\mu_{k}=g(h_{1},\ldots,h_{k},f)\)</span>, <span class="math">\(|\mu_{k}|\ge2\delta\)</span></td>
<td>Model: <span class="math">\(\mu_{k}=g(h_{1},\ldots,h_{k},o)\)</span>, <span class="math">\(|\mu_{k}|\ge\delta\)</span></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>SL: <span class="math">\(H=G(h_{1},\ldots,h_{k})\)</span>, <span class="math">\(\Pr[H=f]\ge1-\delta\)</span></td>
<td>Violation of hardness: <span class="math">\(H=G(h_{1},\ldots,h_{k})\)</span>, <span class="math">\(\Pr[H=f]&gt;1-\delta\)</span></td>
<td>Violation of pseudo-density <span class="math">\(H=G(h_{1},\ldots,h_{k})\)</span>, <span class="math">\(H(U)\le\delta H(S)-\varepsilon\)</span></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>Assumption</td>
<td>WL never fails</td>
<td>Violation is impossible</td>
<td>Violation of pseudo-density is impossible</td>
<td>Actually dense</td>
</tr>
<tr class="row-odd"><td>Conclusion</td>
<td>SL works</td>
<td>Hard-core measure exists, with same <span class="math">\(k\)</span>, <span class="math">\(G\)</span>, <span class="math">\(g\)</span></td>
<td>Model exists</td>
<td>Model exists</td>
</tr>
<tr class="row-even"><td>Algorithmic</td>
<td>Weak learner requirement</td>
<td>Approximately optimal weak learner</td>
<td>Approximately optimal distinguisher</td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<table border="1" class="docutils">
<colgroup>
<col width="4%" />
<col width="36%" />
<col width="25%" />
<col width="29%" />
<col width="5%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Setting</th>
<th class="head">Boosting</th>
<th class="head">Hard-core measure</th>
<th class="head">DMT/transference principle</th>
<th class="head">Weak regularity</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>&#160;</td>
<td>WL: <span class="math">\(|\mu_{i}|\ge2\delta\)</span>, <span class="math">\(\mu_{i}=g(h_{1,}\ldots,h_{i},f)\)</span>, <span class="math">\(h_{i+1}\in\mathcal{T}\)</span>, <span class="math">\(k\)</span> iterations</td>
<td>Hardcore measure: <span class="math">\(\mu_{k}=g(h_{1},\ldots,h_{k},f)\)</span>, <span class="math">\(|\mu_{k}|\ge2\delta\)</span></td>
<td>Model: <span class="math">\(\mu_{k}=g(h_{1},\ldots,h_{k},o)\)</span>, <span class="math">\(|\mu_{k}|\ge\delta\)</span></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>SL: <span class="math">\(H=G(h_{1},\ldots,h_{k})\)</span>, <span class="math">\(\Pr[H=f]\ge1-\delta\)</span></td>
<td>Violation of hardness: <span class="math">\(H=G(h_{1},\ldots,h_{k})\)</span>, <span class="math">\(\Pr[H=f]&gt;1-\delta\)</span></td>
<td>Violation of pseudo-density <span class="math">\(H=G(h_{1},\ldots,h_{k})\)</span>, <span class="math">\(H(U)\le\delta H(S)-\varepsilon\)</span></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>Assumption</td>
<td>WL never fails</td>
<td>Violation is impossible</td>
<td>Violation of pseudo-density is impossible</td>
<td>Actually dense</td>
</tr>
<tr class="row-odd"><td>Conclusion</td>
<td>SL works</td>
<td>Hard-core measure exists, with same <span class="math">\(k\)</span>, <span class="math">\(G\)</span>, <span class="math">\(g\)</span></td>
<td>Model exists</td>
<td>Model exists</td>
</tr>
<tr class="row-even"><td>Algorithmic</td>
<td>Weak learner requirement</td>
<td>Approximately optimal weak learner</td>
<td>Approximately optimal distinguisher</td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<p>Some comments:</p>
<ol class="arabic">
<li><p class="first">Boosting: Note it’s important that the <span class="math">\(\delta\)</span> here is the
same; many boosting algorithms meet this criterion. The theorem says
that “either weak learner fails or strong learner works.”</p>
<p>In boosting, we think of weak learner as never failing.</p>
</li>
<li><p class="first">Hard-core measure lemma: The lemma says that either we can find
hard-core measure, on which no function can compute the function
<span class="math">\(f\)</span> more than <span class="math">\(1/2 +\delta\)</span> of time; or find a function
computing <span class="math">\(f\)</span> <span class="math">\(1-\delta\)</span> of the time.</p>
<p>Here, we want to come up with the measure. Although the logical
format is the same as boosting, here we assume that the violations
never happen (there is no strong learner). Every boosting algorithm
gives hard-core measure lemma with the same parameters, and with
exactly the same way of “gluing” the functions. Sometime you care
about computational complexity of <span class="math">\(G\)</span> but not of <span class="math">\(g\)</span>, or
vice versa.</p>
</li>
<li><p class="first">We can convert the hard-core measure theorem into the dense model
theorem/transference principle (Tao and Ziegler).</p>
<p>Here, we have a distribution we’re trying to model. Either the
distribution has pseudo-density property— there isn’t a violation
that’s definable from <span class="math">\(k\)</span> different properties from hypothesis
class, where violation means that the expected value is much smaller
on <span class="math">\(U\)</span> than on <span class="math">\(S\)</span>—or we get a model of density
<span class="math">\(\ge \delta\)</span>. Assuming that violation of pseudo-density does
not happen, we get a model.</p>
</li>
<li><p class="first">Weak regularity is just DMT except the distribution actually is
dense. It’s not so interesting that it has a dense model.</p>
<p>What we get is that the dense model you get is simple, definable in
terms of a small number of basic hypotheses.</p>
<p>Sometimes we care about simplicity in the model, and sometimes
simplicity in <span class="math">\(G\)</span>.</p>
</li>
<li><p class="first">Note the <span class="math">\(k\)</span> is the same throughout. Reductions preserves
<span class="math">\(k\)</span>, and the functions <span class="math">\(h_i, G\)</span>.</p>
<p>We don’t only have the fact that boosting implies hard-core lemma
implies regularity lemma. We have the stronger result that whatever
boosting algorithm you give me, I get a hard-core lemma and
regularity lemma with the same parameters and algorithm. Thus we can
pick the boosting algorithm that gives the best results for our
application.</p>
</li>
</ol>
</div>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<p>First we discuss the PAC learning model.</p>
<p>Let <span class="math">\(U\)</span> be a set, and by abuse of notation, also a distribution on
that set. (Think of <span class="math">\(U\)</span> as the universe, the set of possible
inputs.) For simplicity, take the distribution to be uniform. Let
<span class="math">\(f:U\to \{0,1\}\)</span> be a boolean function. A learning algorithm can
request any number of points <span class="math">\((x,f(x))\)</span> where <span class="math">\(x\sim U\)</span>. The
goal is to find a hypothesis <span class="math">\(h\)</span> such that</p>
<div class="math">
\[\Pr_{x\sim U} [h(x)=f(x)]\ge 1-\delta.\]</div>
<p>A for <span class="math">\((U,f)\)</span> with hypothesis class <span class="math">\(\mathcal H\)</span> is an
algorithm such that given samples <span class="math">\((x,f(x)), x\sim U\)</span>, outputs
<span class="math">\(h\in \mathcal H\)</span> (with high probability) such that</p>
<div class="math">
\[\Pr_{x\sim U}[h(x)=f(x)]\ge 1-\delta.\]</div>
<p>(Typically, we say that the probability of success is
<span class="math">\(1-\varepsilon\)</span>, ask for a strong learner for all
<span class="math">\(f\in \mathcal F\)</span>, and require it to run in time
<span class="math">\(\operatorname{poly}(1/\varepsilon, 1/\delta)\)</span>.)</p>
<p>In boosting, we assume that we have weak learners.</p>
<p>A <span class="math">\(\varepsilon\)</span>- for <span class="math">\((\mu, f)\)</span> with hypothesis class
<span class="math">\(\mathcal H\)</span> is an algorithm such that given
<span class="math">\((x,f(x)), x\sim \mu\)</span>, outputs <span class="math">\(h\)</span> (with high probability)
such that</p>
<div class="math">
\[\Pr_{x\sim \mu} [h(x)=f(x)] \ge \frac{1}{2}+\varepsilon.\]</div>
<p>It only has to output a function that is somewhat correlated with the
right answer. Typically, we ask the weak learner to work on any
distribution <span class="math">\(\mu\)</span> satisfying some assumptions.</p>
<p>In order to use a weak learner, we construct a routine that subsamples
the distribution <span class="math">\(U\)</span> to pass to pass to the weak learner.</p>
<p>Let <span class="math">\(\mu:U\to [0,1]\)</span>. Define the probability distribution <a class="footnote-reference" href="#id3" id="id1">[1]</a></p>
<div class="math">
\[D_\mu(x) = \frac{\mu(x)}{\sum_{x'\in U}\mu(x')}.\]</div>
<p>Think of this as rejection sampling: pick <span class="math">\(x\sim U\)</span>, keep it with
probability in <span class="math">\([0,1]\)</span>, or else throw if back and repeat.</p>
<p>In order for this sampling to be efficient, we need <span class="math">\(\mu\)</span> to not
be too small.</p>
<p>Define the of <span class="math">\(\mu\)</span> in <span class="math">\(U\)</span> to be</p>
<div class="math">
\[|\mu| = \operatorname{E}_{x\in U} \mu(x).\]</div>
<p>We will use weak learners in the following context.</p>
<ol class="arabic">
<li><p class="first">We will only run weak learners on distributions whose density is not
too small (the dependence on <span class="math">\(\delta\)</span> is
<span class="math">\(|\mu|=\Omega(\delta)\)</span>). We don’t want to run a weak learner on
a distribution of very low density, because the time to simulate the
distribution is inversely proportional to the density.</p>
</li>
<li><p class="first">We ask the weak learners to output a function in a given class
<span class="math">\(h\in \mathcal T\)</span>.</p>
<p>Then it will turn out that that both the measures that we run the
weak learners on, and the final hypothesis, will be describable using
<span class="math">\(\mathcal F_l \mathcal T\)</span> (see below), for some class
<span class="math">\(\mathcal F\)</span>.</p>
</li>
</ol>
<p>Say that a set <span class="math">\(\mathcal T\)</span> of functions <span class="math">\(U\to \{0,1\}\)</span> form
a class if <span class="math">\(f\in \mathcal T\)</span> implies <span class="math">\(1-f \in \mathcal T\)</span>.</p>
<p>Let <span class="math">\(\mathcal F\)</span> be a class of boolean functions. Define the class
of functions</p>
<div class="math">
\[\mathcal F_k \mathcal T = \{f(h_1(x),\ldots, h_k(x)) : f\in\mathcal F, h_1,\ldots, h_k\in \mathcal T\}.\]</div>
</div>
<div class="section" id="boosting-and-the-hard-core-lemma">
<h1>Boosting and the Hard-core lemma<a class="headerlink" href="#boosting-and-the-hard-core-lemma" title="Permalink to this headline">¶</a></h1>
<p>The first boosting algorithm we give is totally ridiculous from the ML
point of view. For people who work on weak regularity on graphs this is
the natural version, and leads to the standard versions of results.</p>
<p>We will take <span class="math">\(\mathcal F\)</span> to be the set of all boolean functions,
so given hypotheses <span class="math">\(h_1,\ldots, h_k\)</span>, we can choose the best
predictor using <span class="math">\(h_1(x),\ldots, h_k(x)\)</span>.</p>
<p>[Boosting with decision trees][thm:boosting] Let <span class="math">\(U\)</span> be a
distribution, <span class="math">\(\mathcal T\)</span> a class of boolean functions
<span class="math">\(U\to \{0,1\}\)</span>, <span class="math">\(\mathcal F\)</span> the class of all boolean
functions. Let <span class="math">\(f:U\to \{0,1\}\)</span> be a given function (which we are
trying to learn).</p>
<ol class="arabic">
<li><p class="first">Suppose that there is a <span class="math">\(\delta\)</span>-weak learner such that given
any distribution <span class="math">\(\mu\)</span> on <span class="math">\(U\)</span> with
<span class="math">\(|\mu|\ge 2\delta\)</span>, it produces <span class="math">\(h\in \mathcal T\)</span> such
that</p>
<div class="math">
\[\Pr_{x\sim \mu} [h(x) = f(x)] \ge \frac{1}{2}+ \varepsilon.\]</div>
</li>
<li><p class="first">Then there is a strong learner that produces
<span class="math">\(h\in \mathcal F_k\mathcal T\)</span> with
<span class="math">\(k\le\lceil 1/\varepsilon^2\delta^2\rceil\)</span> such that <a class="footnote-reference" href="#id4" id="id2">[2]</a></p>
<div class="math">
\[\Pr_{x\sim U} [h(x) = f(x)]\ge 1-\delta.\]</div>
</li>
</ol>
<p>[Hard-core lemma] [thm:hardcore] Let <span class="math">\(U\)</span> be a distribution,
<span class="math">\(\mathcal T\)</span> a class of boolean functions <span class="math">\(U\to \{0,1\}\)</span>,
<span class="math">\(\mathcal F\)</span> the class of all boolean functions.</p>
<p>Then either</p>
<ol class="arabic">
<li><p class="first">There exists <span class="math">\(h\in \mathcal F_k \mathcal T\)</span> such that</p>
<div class="math">
\[\Pr_{x\sim U} [h(x)=f(x)] \ge 1-\delta,\]</div>
<p>where <span class="math">\(k \le 1/\varepsilon^2\delta^2\)</span>, or</p>
</li>
<li><p class="first">(There exists a hard-core distribution.) There exists
<span class="math">\(|\mu|\ge 2\delta\)</span> on <span class="math">\(U\)</span>, such that for all
<span class="math">\(h\in \mathcal T\)</span>,</p>
<div class="math">
\[\Pr_{x\sim \mu}[h(x) = f(x)] \le \frac{1}{2}+\varepsilon.\]</div>
</li>
</ol>
<p>Note it is important for us to keep track of the size of the hardcore
distribution, which is <span class="math">\(\ge 2\delta\)</span> here. Different boosting
algorithms will give the result for different classes of functions
<span class="math">\(\mathcal F\)</span>.</p>
<p>[Proof of hard-core lemma&nbsp;[thm:hardcore] from boosting&nbsp;[thm:boosting]]
Let weak learner be exhaustive search over <span class="math">\(\mathcal T\)</span>. The weak
learner operates on distributions <span class="math">\(|\mu_i|\ge 2\delta\)</span>. If it
always produces <span class="math">\(h_i\)</span> with bias <span class="math">\(\ge \delta\)</span>, then continue
and obtain the strong learner: we get some
<span class="math">\(H\in \mathcal F_k \mathcal T\)</span> such that <span class="math">\(H(x)=f(x)\)</span> with
probability <span class="math">\(1-\delta\)</span>.</p>
<p>If at some step <span class="math">\(i\)</span> our exhaustive search algorithm gets stuck, we
get a distribution <span class="math">\(\mu_i\)</span> that’s hard-core.</p>
</div>
<div class="section" id="dense-model-theorem">
<h1>Dense model theorem<a class="headerlink" href="#dense-model-theorem" title="Permalink to this headline">¶</a></h1>
<p>For a set <span class="math">\(S\subseteq U\)</span> and a function <span class="math">\(T:U \to \{0,1\}\)</span>,
let <span class="math">\(T(S):=\operatorname{E}_{x\in S} T(x)\)</span>. (For a measure
<span class="math">\(\mu: U\to [0,1]\)</span>, also write
<span class="math">\(T(\mu) = \operatorname{E}_{x\sim \mu} T(x)\)</span>.)</p>
<p>Let <span class="math">\(S\subseteq U\)</span> be a subset, and let <span class="math">\(\mathcal T\)</span> be a
set of tests. <span class="math">\(S\)</span> is if for all <span class="math">\(T\in \mathcal T\)</span>,</p>
<div class="math">
\[T(U) \ge \delta T(S)-\varepsilon.\]</div>
<p>Think of saying that the tests <span class="math">\(\mathcal T\)</span> don’t reveal that the
set <span class="math">\(S\)</span> is small.</p>
<ol class="arabic simple">
<li>One way of being pseudo-dense is to actually be dense.</li>
<li>Another, one step removed, is that there’s a set <span class="math">\(R\)</span> (or more
generally, a measure <span class="math">\(\mu\)</span>) that’s indistibguishable from
<span class="math">\(S\)</span> by <span class="math">\(\mathcal T\)</span>, and such that <span class="math">\(R\)</span> occupies at
least a <span class="math">\(\delta\)</span> fraction of <span class="math">\(U\)</span>.</li>
</ol>
<ul class="simple">
<li></li>
</ul>
<p>For two distributions <span class="math">\(\mu_1,\mu_2\)</span> on <span class="math">\(U\)</span>, we say that
<span class="math">\(\mu_1,\mu_2\)</span> are indistinguishable by tests in <span class="math">\(\mathcal T\)</span>
up to <span class="math">\(\varepsilon\)</span>, written <span class="math">\(\mu_1 \sim_{\mathcal T} \mu_2\)</span>
within <span class="math">\(\varepsilon\)</span>, if for every <span class="math">\(T\in \mathcal T\)</span>,</p>
<div class="math">
\[|\operatorname{E}_{\mu_1}T - \operatorname{E}_{\mu_2} T| \le \varepsilon.\]</div>
<p>[Dense model theorem][thm:dmt] Let <span class="math">\(\mathcal T\)</span> be a class of
tests <span class="math">\(U\to \{0,1\}\)</span>.</p>
<p>If <span class="math">\(S\)</span> is <span class="math">\((\varepsilon,\delta)\)</span>-pseudodense against
<span class="math">\(F_k\mathcal T\)</span>, <span class="math">\(k=O(1/\varepsilon^2\delta^2)\)</span> then there
exists <span class="math">\(\mu\)</span>, <span class="math">\(\mu\in F_k\cal T\)</span> such that
<span class="math">\(|\mu|\ge \frac{\delta}{1+\delta}-O(\varepsilon)\)</span> and
<span class="math">\(D_\mu\sim_{\cal T} S\)</span> to within <span class="math">\(O(\varepsilon/\delta)\)</span>.</p>
<p>The idea in the proof is to use the Hard-core lemma, with the hard
function being membership in <span class="math">\(S\)</span>.</p>
<p>Let <span class="math">\(U'\)</span> be the following distribution: let
<span class="math">\(\delta'=\frac{\delta}{1+\delta}\)</span> and</p>
<ol class="arabic simple">
<li>with probability <span class="math">\(\delta'\)</span>, take <span class="math">\(x\in S\)</span> and output
<span class="math">\((0,x)\)</span></li>
<li>with probability <span class="math">\(1-\delta'\)</span>, take <span class="math">\(x\in U\)</span> and output
<span class="math">\((1,x)\)</span>.</li>
</ol>
<p>Define a test <span class="math">\(T\in \mathcal T\)</span> to operate on an example
<span class="math">\((y, x)\)</span> by <span class="math">\(T(y,x)=T(x)\)</span>. For
<span class="math">\(T\in \mathcal F_k \mathcal T\)</span>,</p>
<div class="math">
\[\begin{split}\begin{aligned}
\Pr_{U'}[T((y,x))=y] &amp;= \delta' T(S) + (1-\delta') (1-T(U)) \\
   &amp;= 1-\delta' + \delta' (T(S)) - (1-\delta') T(U)\\
   &amp;= 1-\delta' + \frac{1}{1+\delta} (\delta T(S) - T(U))\\
   &amp;\le 1-\delta'+\varepsilon.\end{aligned}\end{split}\]</div>
<p>No test in <span class="math">\(\mathcal F_k \mathcal T\)</span> can be correct with
probability <span class="math">\(&gt;\delta'-\varepsilon\)</span>. By the Hard-core
Lemma&nbsp;[thm:hardcore], there exists
<span class="math">\(|\mu'|\ge 2(\delta'-\varepsilon)\)</span> such that for any
<span class="math">\(T\in \mathcal T\)</span>,
<span class="math">\(\Pr_{(x,y) \sim U'}[T(x)=y]\le  \frac{1}{2}+\varepsilon\)</span>.</p>
<p>In order for <span class="math">\(\mu'\)</span> to be hardcore, it must be split approximately
evenly between <span class="math">\(U\)</span> and <span class="math">\(S\)</span> (up to <span class="math">\(\varepsilon\)</span>);
otherwise; we could have an advantage by predicting constant 0 or 1.
Thus each part has at least
<span class="math">\(2(\delta'-\varepsilon) (1/2 - \varepsilon) = \delta'(1-O(\varepsilon/\delta))\)</span>
of the mass. Then</p>
<div class="math">
\[D_{\mu'|_U}\sim_{O(\varepsilon)} D_{\mu'|_S}\sim_{O(\varepsilon/\delta)} S.\]</div>
</div>
<div class="section" id="proof-for-boosting">
<h1>Proof for boosting<a class="headerlink" href="#proof-for-boosting" title="Permalink to this headline">¶</a></h1>
<p>[Proof of Theorem&nbsp;[thm:boosting]] The algorithm is as follows. Let
<span class="math">\(WL(\mu)\)</span> denote the weak learner operating on <span class="math">\((\mu, f)\)</span>.</p>
<p>Let <span class="math">\(\mu_0\)</span> be constant 1, <span class="math">\(i=0\)</span>.</p>
<p>While <span class="math">\(|\mu_i|\ge 2\delta\)</span>, do</p>
<ul>
<li><p class="first"><span class="math">\(h_{i+1}\mapsfrom WL(\mu_i)\)</span>.</p>
</li>
<li><p class="first">Partition <span class="math">\(U\)</span> according to values of <span class="math">\(h_1,\ldots,h_i\)</span>.</p>
<p>Let <span class="math">\(h_{1:i}(x):= (h_1(x),\ldots, h_i(x))\in \{0,1\}^i\)</span>, and
let <span class="math">\(B_i(x)\)</span> be the “block” that <span class="math">\(x\)</span> is in,</p>
<div class="math">
\[B_i(x) = h_{1:i}^{-1}(h_{1:i}(x)) = \{y\in U : h_{1:i}(x)=h_{1:i}(y)\}.\]</div>
<p>For a set <span class="math">\(B\)</span>, let <span class="math">\(\operatorname{Maj}(B)\)</span> denote the
majority value of <span class="math">\(f\)</span> on <span class="math">\(B\)</span>.</p>
</li>
<li><p class="first">Define <span class="math">\(\mu_{i+1}\)</span> by</p>
<div class="math">
\[\begin{split}\mu_{i+1}(x) = \begin{cases}
\frac{1-p_{\operatorname{Maj}, B_i(x)}}{p_{\operatorname{Maj}, B_i(x)}},&amp;\text{if } f(x)=\operatorname{Maj}(B_i(x))\\
1,&amp;\text{otherwise}
\end{cases}•\end{split}\]</div>
<p>where
<span class="math">\(p_{\operatorname{Maj},B} = \Pr(f(y) = \operatorname{Maj}(B)| y\in B)\)</span>,
the proportion of the majority in <span class="math">\(B\)</span>.</p>
</li>
<li><p class="first"><span class="math">\(i\mapsfrom i+1\)</span>.</p>
</li>
</ul>
<p>Finally, return <span class="math">\(H_{i}(x) = \operatorname{Maj}({B_{i}(x)})\)</span>, i.e.,
look at the block that <span class="math">\(x\)</span> is in, and choose the majority value.</p>
<p>Note that the measure <span class="math">\(\mu_{i+1}\)</span> rebalances each block
<span class="math">\(B_i\)</span> such that conditioned on <span class="math">\(y\)</span> being in a block
<span class="math">\(B_i(x)\)</span>,</p>
<div class="math">
\[\Pr_{y\sim \mu_{i+1}}(f(y)=1|y\in B_i(x)) = \Pr_{y \sim \mu_{i+1}}(f(y)=0|y\in B_i(x))=\frac{1}{2}.\]</div>
<p>Indeed, we have</p>
<div class="math">
\[\begin{split}\begin{aligned}
\operatorname{E}_{y\sim U}[\mathbf{1}_{f(y)=1}
 \mu_{i+1}(y) |y\in B_i(x)]
 &amp;=p_{\operatorname{Maj}, B_i(x)} \frac{1-p_{\operatorname{Maj}, B_i(x)}}{p_{\operatorname{Maj}, B_i(x)}} = 1-p_{\operatorname{Maj}, B_i(x)}\\
 \operatorname{E}_{y\sim U}[\mathbf{1}_{f(y)=0}
 \mu_{i+1}(y) |y\in B_i(x)]
 &amp;=\left(1-p_{\operatorname{Maj}, B_i(x)}\right)\cdot 1 = 1-p_{\operatorname{Maj}, B_i(x)}\\
|\mu_{i+1}| =  \operatorname{E}_{y\sim U}[
 \mu_{i+1}(y)]&amp;=\sum_{\text{block }B_i} [2(1-p_{\operatorname{Maj}, B_i}) \Pr(B_i)]\\
 &amp; \ge 2(1-p_{\operatorname{Maj},U}).\end{aligned}\end{split}\]</div>
<p>Note that if <span class="math">\(|\mu_{i+1}|\le 2\delta\)</span>, then
<span class="math">\(\Pr_{x\in X}[H_i=f]\ge 1-\delta\)</span>, and we are done. (We stop
before we have to apply the weak learner to a distribution of density
<span class="math">\(&lt;\delta\)</span>.)</p>
<p>We need to show this method terminates in a bounded number of steps.</p>
<p>Consider the potential function</p>
<div class="math">
\[\varphi_i = \operatorname{E}_{x\sim U} [(\Pr[f=1|B_i(x)])^2]
 = \operatorname{E}_{x\sim U} [\operatorname{E}[ f|B_i]^2]\]</div>
<p>(Think of <span class="math">\(B_i\)</span> as a partition; for a partition,
<span class="math">\(\operatorname{E}[f|P]\)</span> is a function of <span class="math">\(x\)</span> that takes
<span class="math">\(x\)</span> to the average value in the atom of the partition that
contains <span class="math">\(x\)</span>.) Note this have value in <span class="math">\([0,1]\)</span> and is
maximized if <span class="math">\(f\)</span> is constant on every block. We show every
iteration increases this potential function by at least a fixed amount,
<span class="math">\((\varepsilon\delta)^2\)</span>. Fix a block <span class="math">\(B\)</span> in the partition.
Define <span class="math">\(p,q,\alpha_+,\alpha_-,p_0,p_1\)</span> as follows.</p>
<div class="math">
\[\begin{split}\begin{aligned}
p&amp;=\Pr[f=1|B]\\
q&amp;=\Pr[h_{i+1} = 1|B]\\ q+\alpha_+ &amp;= \Pr[h_{i+1}=1|B, f=1]\\ q-\alpha_- &amp;= \Pr[h_{i+1}=1|B, f=0]\\ \alpha_+p &amp;= \alpha_-(1-p) \text{ by conservation}\\
p_0&amp;= \Pr[f=1|h=0,B] = \frac{\Pr[f=1\wedge h=0|B]}{\Pr[h=0|B]} = \frac{p(1-q-\alpha_+)}{1-q}\\
p_1&amp;= \Pr[f=1|h=1,B] = \frac{\Pr[f=1\wedge h=1|B]}{\Pr[h=1|B]} = \frac{p(q+\alpha_+)}{q}\\
\operatorname{E}_{x\in B} [\operatorname{E}[f|B_{i+1}]^2]&amp;=qp_1^2 + (1-q)p_0^2 = p^2 \left(\frac{(q+\alpha_+)^2}{q} + \frac{(1-q-\alpha_+)^2}{1-q}\right) \\
&amp;=p^2\left(
\left(q+2\alpha_+ + \frac{\alpha_+^2}{q}\right)
+
\left(1-q-2\alpha_+ + \frac{\alpha_+^2}{1-q}\right)\right)
\\
&amp;=p^2\left(1+\frac{\alpha_+^2}{q} + \frac{\alpha_+^2}{1-q}\right)\\
&amp;\ge p^2 + 4p^2 \alpha_+^2 \ge
p^2+
 \alpha_+^2\\
 \operatorname{E}[f|B_{i+1}]^2 - \operatorname{E}[f|B_i]^2&amp;=\alpha_+^2(B_i(x)).\end{aligned}\end{split}\]</div>
<p>Assume WLOG that <span class="math">\(\operatorname{Maj}(B_i(x))=1\)</span>. (Otherwise the
LHS is smaller.)</p>
<div class="math">
\[\begin{split}\begin{aligned}
\operatorname{E}_{x\in B}[\mu(x) ((-1)^{(h(x)\ne f(x))})]
&amp;=\quad p\left(\frac{1-p}{p}\right) \left[(q+\alpha_+) - (1-q-\alpha_+)\right]&amp;(f=1)\\
&amp;\quad +(1-p) 1 [1-(1-\alpha_-) - (q-\alpha_-)]&amp;(f=0)\\
&amp;=(1-p) (2\alpha_++2\alpha_-)\\
&amp;= 2\alpha_+(1-p) + 2\alpha_+p=2\alpha_+\\
\operatorname{E}_{x\sim U} 2\alpha_+(B_i(x))
&amp;=\operatorname{E}_{x\sim U} [\mu(x) ((-1)^{h(x)\ne f(x)})]\\
&amp;\ge \varepsilon|\mu| \ge 2\delta \varepsilon\\
\varphi_{i+1}-\varphi_i &amp;\ge
\operatorname{E}_{x\sim U} [\operatorname{E}[f|B_{i+1}]^2 - \operatorname{E}[f|B_i]^2]\\
&amp;\ge
\operatorname{E}_{x\sim U} \alpha_+^2(B_i(x))\ge  (\delta\varepsilon)^2.\end{aligned}\end{split}\]</div>
<p>• Because <span class="math">\(\varphi_i\)</span> is always in <span class="math">\([0,1]\)</span>, the number of
iterations is at most <span class="math">\(k\le (\delta \varepsilon)^2\)</span>.</p>
</div>
<div class="section" id="comments-regularity-lemmas">
<h1>Comments, Regularity lemmas<a class="headerlink" href="#comments-regularity-lemmas" title="Permalink to this headline">¶</a></h1>
<p>Some comments:</p>
<ol class="arabic">
<li><p class="first">All you get from this proof is a decision tree; the complexity is
exponential in <span class="math">\(k\)</span>. This is a bug, not a feature.</p>
<p>In complexity terms, we don’t get good hard-core measure, because the
circuit size for the outer function <span class="math">\(G\)</span> is <span class="math">\(2^k\)</span>. A
better boosting algorithm would give <span class="math">\(G\)</span> have smaller
complexity. If your stopping point is the hard-core lemma, this is
not the boosting algorithm you want. For the dense model theorem,
this is fine because all you care about is size of <span class="math">\(k\)</span>, not the
complexity of <span class="math">\(G\)</span>.</p>
<p>There is another boosting algorithm which gives a weighted majority
function, which is a simpler function. A weighted majority can be
converted into a decision tree, but not vice versa.</p>
</li>
<li><p class="first">This potential function matches this boosting algorithm. Other
boosting algorithms can be analyzed with other potential functions.
This is like the potential function used most in graph theory. Key
property: you can’t make negative progress; you always go forwards.</p>
</li>
<li><p class="first">For Szemeredi regularity, we need a stronger boosting theorem.
Suppose we get stuck at some step: no function correlates globally,
but there are many blocks where we can find functions that correlate
with the function inside that block. If in <span class="math">\(\varepsilon\)</span>
fraction of blocks we find functions that correlate, partition them
based on all the values of these functions, and repeat.</p>
<p>In one step we’ve gone from order of <span class="math">\(2^k\)</span> to order of
<span class="math">\(2^{2^k}\)</span> buckets, and increased the potential function by a
polynomial in terms of <span class="math">\(\varepsilon,\delta\)</span>. This is a familiar
argument; we can only go <span class="math">\(\frac{1}{\varepsilon}\)</span> iterations
before we terminate. This time, the number of sets is a tower
depending on <span class="math">\(\varepsilon\)</span>.</p>
</li>
<li><p class="first">Regularity lemmas:</p>
<p>Fix a set of vertices <span class="math">\(V\)</span> of set <span class="math">\(n\)</span>. Let <span class="math">\(U\)</span> be
edges in complete graph on <span class="math">\(V\)</span>. (We can also consider the case
when <span class="math">\(U\)</span> is not the complete graph, ex. <span class="math">\(U\)</span> is the edges
in <span class="math">\(d\)</span>-regular expander on <span class="math">\(V\)</span>.)</p>
<p>The underlying set we care about is the set of cuts defined by
<span class="math">\(A,B\subseteq V\)</span> where <span class="math">\(A\cap B=\phi\)</span>; there are
<span class="math">\(3^k\)</span> of them.</p>
<p>If <span class="math">\(|E|\ge \delta \binom n2\)</span>, the generic regularity lemma says
there exists <span class="math">\(\mu=G(T_1,\ldots, T_k)\)</span>, where
<span class="math">\(k=O(1/\varepsilon^2\delta^2)\)</span>, that is a good predictor the
number of edges of any cut in the graph. Use the <span class="math">\(T\)</span>’s to
divide the vertices into <span class="math">\(3^k\)</span> subsets such that <span class="math">\(\mu\)</span> is
a constant on every pair of subsets.</p>
<div class="math">
\[\frac{E_G(A,B)}{|E_G|}
\approx_\varepsilon \sum_{i,j}
\mu_{ij}
\frac{|A\cap A_i||B\cap B_j|}{|V|^2}.\]</div>
<p>This is the weak regularity of Frieze-Kannan. For Szemeredi we need
the stronger boosting lemma (see previous point).</p>
<p>We can also do something similar with <span class="math">\(G\)</span> a subset of an
expander. The expander mixing lemma gives an error term.</p>
</li>
</ol>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>When <span class="math">\(U\)</span> is not uniform and has distribution <span class="math">\(u(x)\)</span>, this
is <span class="math">\(\frac{\mu(x)u(x)}{\sum_{x'\in U} \mu(x')u(x')}\)</span>.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>We ignore sample complexity here. In reality, because we only see
<span class="math">\(U\)</span> from samples, we need to think about generalization. If the
VC-dimension of <span class="math">\(\mathcal T\)</span> is <span class="math">\(d\)</span>, then the
VC-dimension of <span class="math">\(\mathcal F_k\mathcal H\)</span> is at most
<span class="math">\(k^d\)</span>. In ML we don’t want to take <span class="math">\(\mathcal F\)</span> to be the
class of all boolean functions. For this theorem, let’s just assume
we are actually given all pairs <span class="math">\((x,f(x))\)</span>.</td></tr>
</tbody>
</table>
</div>


          </div>
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2017, Simons Institute.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.5.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="../_sources/groups/models.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>